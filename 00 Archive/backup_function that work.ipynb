{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO # Library to train AI models in reinforcement learning  \n",
    "\n",
    "\n",
    "class TradinEnv_v1(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Trading Environment for Reinforcement Learning.\n",
    "\n",
    "    The agent can take actions (buy, sell, hold) based on market indicators.\n",
    "    The goal is to maximize profit while using stop-loss and take-profit levels.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the trading environment.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): Historical market data with indicators.\n",
    "        \"\"\"\n",
    "        super(TradinEnv_v1, self).__init__()\n",
    "\n",
    "        # Store the dataset and set initial step \n",
    "        self.df = df\n",
    "        self.current_step = 0 \n",
    "        self.balance = 1000 # Initial capital\n",
    "        self.position = None # No active trade   \n",
    "        self.pending_orders = []  # Store multiple pending orders\n",
    "\n",
    "        # Define action space: 3 possible actions (0 = Hold, 1 = Buy, 2 = Sell)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # Define the observation space: all columns of the dataset\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(len(df.columns),), dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self): \n",
    "        \"\"\"\n",
    "        Reset the environment at the start of a new episode.\n",
    "\n",
    "        Returns:\n",
    "        np.array: First observation (market indicators at step 0)\n",
    "        \"\"\"\n",
    "        self.current_step = 0\n",
    "        #self.balance = 1000\n",
    "        self.position = None\n",
    "        self.pending_orders = []\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        \"\"\"\n",
    "        Retrieve the current market state.\n",
    "\n",
    "        Returns:\n",
    "        np.array: Market indicators at the current step.\n",
    "        \"\"\"\n",
    "        return self.df.iloc[self.current_step].values\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Execute an action (buy, sell, hold) and update the environment.\n",
    "\n",
    "        Parameters:\n",
    "        action (int): 0 (Hold), 1 (Buy), 2 (Sell)\n",
    "\n",
    "        Returns:\n",
    "        tuple: (new observation, reward, done flag, info)\n",
    "        \"\"\"\n",
    "        current_price = self.df.iloc[self.current_step]['close']\n",
    "        high = self.df.iloc[self.current_step]['high']\n",
    "        low = self.df.iloc[self.current_step]['low']\n",
    "\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Handle new actions\n",
    "        if action == 1:  # Buy limit order\n",
    "            self.position = \"long\"\n",
    "            print(f\"step ceck: \\n Position: {self.position}, action: {action}, current step: {self.current_step}\")\n",
    "            self._place_order(\"buy\", high)\n",
    "        elif action == 2:  # Sell limit order\n",
    "            self.position = \"short\"\n",
    "            print(f\"step ceck: step ceck: Position: {self.position}, action: {action}, current step: {self.current_step}\")\n",
    "            self._place_order(\"sell\", low)\n",
    "        # Process existing pending orders\n",
    "        self._execute_pending_orders(current_price, high, low)\n",
    "        if action == 0: \n",
    "            self.position = None\n",
    "\n",
    "\n",
    "        # Move to the next step\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= len(self.df) - 1:\n",
    "            done = True\n",
    "        \n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "    def _place_order(self, order_type, entry_price):\n",
    "        \"\"\"\n",
    "        Place a limit order.\n",
    "\n",
    "        Parameters:\n",
    "        order_type (str): 'buy' or 'sell'.\n",
    "        entry_price (float): Price at which the order will be executed.\n",
    "        \"\"\"\n",
    "        order = {\n",
    "            \"type\": order_type,\n",
    "            \"entry_price\": entry_price,\n",
    "            \"step_placed\": self.current_step\n",
    "        }\n",
    "        self.pending_orders.append(order)\n",
    "\n",
    "    def _execute_pending_orders(self, current_price, high, low):\n",
    "        \"\"\"\n",
    "        Execute any pending limit orders if the price condition is met.\n",
    "\n",
    "        Parameters:\n",
    "        current_price (float): Current market price.\n",
    "        high (float): Current high price.\n",
    "        low (float): Current low price.\n",
    "        \"\"\"\n",
    "        executed_orders = []\n",
    "\n",
    "        for order in self.pending_orders:\n",
    "            if order[\"type\"] == \"buy\" and current_price >= order[\"entry_price\"]: #substitute with HIgh ------------------\n",
    "                executed_orders.append(order)\n",
    "                self.balance +=  (self.balance*( (current_price - order[\"entry_price\"])/current_price ) )    \n",
    "                print(f\"Executed orders = {executed_orders}\") #TBR \n",
    "                print(f\"Price exectued - Entry price = {current_price} - {order[\"entry_price\"]}\")#TBR\n",
    "            elif order[\"type\"] == \"sell\" and current_price <= order[\"entry_price\"]:\n",
    "                executed_orders.append(order)\n",
    "                self.balance +=  (self.balance*( -(current_price - order[\"entry_price\"])/current_price ) ) #substitute with low ------------------\n",
    "                print(f\"executed orders = {executed_orders}\") #TBR \n",
    "                print(f\" Price exectued - Entry price = {current_price} - {order[\"entry_price\"]}\") #TBR\n",
    "        # Remove executed orders from the list\n",
    "        self.pending_orders = [o for o in self.pending_orders if o not in executed_orders]\n",
    "        print(f\"pending orders = {self.pending_orders} \\n\")#TBR\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Print the current state of the environment (for debugging).\n",
    "        \"\"\"\n",
    "        print(f\"Step: {self.current_step}, Balance: {self.balance}, Position: {self.position}, Pending Orders: {self.pending_orders}\")\n",
    "\n",
    "# This class compared to the older one adds the element of \"future\", meaning that the order instead of being\n",
    "# immediately executed, is opened as a pending order, and then executed at a later time. This code introduces\n",
    "# limit orders by introducing the term self.pending_order[\"step_placed\"] = self.current_step. This code stores the\n",
    "# current step in a given place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TradinEnv_v1._place_order() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTradinEnv_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_place_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentry_price\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_price\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TradinEnv_v1._place_order() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "TradinEnv_v1._place_order(order_type= \"buy\", entry_price=25, stop_price=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
